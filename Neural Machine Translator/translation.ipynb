{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:55:52.751862Z","iopub.execute_input":"2022-07-15T09:55:52.752279Z","iopub.status.idle":"2022-07-15T09:56:03.429695Z","shell.execute_reply.started":"2022-07-15T09:55:52.752195Z","shell.execute_reply":"2022-07-15T09:56:03.428744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:56:03.431773Z","iopub.execute_input":"2022-07-15T09:56:03.432162Z","iopub.status.idle":"2022-07-15T09:56:09.406541Z","shell.execute_reply.started":"2022-07-15T09:56:03.432109Z","shell.execute_reply":"2022-07-15T09:56:09.405705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install sentencepiece","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:56:09.407789Z","iopub.execute_input":"2022-07-15T09:56:09.408522Z","iopub.status.idle":"2022-07-15T09:56:19.231291Z","shell.execute_reply.started":"2022-07-15T09:56:09.408487Z","shell.execute_reply":"2022-07-15T09:56:19.230088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert') \nmodel = AutoModel.from_pretrained('ai4bharat/indic-bert')","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:56:19.233876Z","iopub.execute_input":"2022-07-15T09:56:19.234532Z","iopub.status.idle":"2022-07-15T09:56:37.341339Z","shell.execute_reply.started":"2022-07-15T09:56:19.234490Z","shell.execute_reply":"2022-07-15T09:56:37.340205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:56:37.343370Z","iopub.execute_input":"2022-07-15T09:56:37.343767Z","iopub.status.idle":"2022-07-15T09:57:01.768195Z","shell.execute_reply.started":"2022-07-15T09:56:37.343727Z","shell.execute_reply":"2022-07-15T09:57:01.767188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown https://drive.google.com/uc?id=1-0wClU9sEjQs1O2wLw0KnN9haAVrZYOd","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:57:01.769690Z","iopub.execute_input":"2022-07-15T09:57:01.770599Z","iopub.status.idle":"2022-07-15T09:57:08.984901Z","shell.execute_reply.started":"2022-07-15T09:57:01.770557Z","shell.execute_reply":"2022-07-15T09:57:08.983957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown https://drive.google.com/uc?id=1-3K-X4Up3FlNiQHDMn0GzhDAGXQDEtUU","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:57:08.986724Z","iopub.execute_input":"2022-07-15T09:57:08.987130Z","iopub.status.idle":"2022-07-15T09:57:12.472968Z","shell.execute_reply.started":"2022-07-15T09:57:08.987074Z","shell.execute_reply":"2022-07-15T09:57:12.471850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown https://drive.google.com/uc?id=1PKpgGgEdowuzFNL41Jf6qd48ZFe4e-yI","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:57:12.474385Z","iopub.execute_input":"2022-07-15T09:57:12.474778Z","iopub.status.idle":"2022-07-15T09:57:16.352191Z","shell.execute_reply.started":"2022-07-15T09:57:12.474738Z","shell.execute_reply":"2022-07-15T09:57:16.350786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown https://drive.google.com/uc?id=1owksQpJA1-BE1xLD1Ewq4Ui-pbVm8WVI","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:57:16.355453Z","iopub.execute_input":"2022-07-15T09:57:16.355878Z","iopub.status.idle":"2022-07-15T09:57:19.338086Z","shell.execute_reply.started":"2022-07-15T09:57:16.355811Z","shell.execute_reply":"2022-07-15T09:57:19.337131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown https://drive.google.com/uc?id=1w-icHfAmAQBVM8YzzNOFJUU_ZZyJSRx5","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:57:19.340450Z","iopub.execute_input":"2022-07-15T09:57:19.341259Z","iopub.status.idle":"2022-07-15T09:57:53.713828Z","shell.execute_reply.started":"2022-07-15T09:57:19.341210Z","shell.execute_reply":"2022-07-15T09:57:53.712856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip ./2epoch.zip","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:57:53.715199Z","iopub.execute_input":"2022-07-15T09:57:53.716400Z","iopub.status.idle":"2022-07-15T09:58:37.749280Z","shell.execute_reply.started":"2022-07-15T09:57:53.716355Z","shell.execute_reply":"2022-07-15T09:58:37.748301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gu_data = []\nf = open('./train.gu')\nfor l in f:\n    gu_data.append(l)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:58:37.750884Z","iopub.execute_input":"2022-07-15T09:58:37.752425Z","iopub.status.idle":"2022-07-15T09:58:45.174989Z","shell.execute_reply.started":"2022-07-15T09:58:37.752380Z","shell.execute_reply":"2022-07-15T09:58:45.174028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pairs = []\nf = open('./train.en')\ni = 0\nfor l in f:\n    train_pairs.append((gu_data[i][:-1],l[:-1]))\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:58:45.176426Z","iopub.execute_input":"2022-07-15T09:58:45.176771Z","iopub.status.idle":"2022-07-15T09:58:48.559915Z","shell.execute_reply.started":"2022-07-15T09:58:45.176737Z","shell.execute_reply":"2022-07-15T09:58:48.559007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gu_test = []\nf = open('./test.gu')\nfor l in f:\n    gu_test.append(l)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:58:48.562804Z","iopub.execute_input":"2022-07-15T09:58:48.563239Z","iopub.status.idle":"2022-07-15T09:58:48.579631Z","shell.execute_reply.started":"2022-07-15T09:58:48.563201Z","shell.execute_reply":"2022-07-15T09:58:48.578919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pairs = []\nf = open('./test.en')\ni = 0\nfor l in f:\n    test_pairs.append((gu_test[i][:-1],l[:-1]))\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:58:48.580673Z","iopub.execute_input":"2022-07-15T09:58:48.581012Z","iopub.status.idle":"2022-07-15T09:58:48.594926Z","shell.execute_reply.started":"2022-07-15T09:58:48.580978Z","shell.execute_reply":"2022-07-15T09:58:48.594157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size = 200000\nsequence_length = 20\nbatch_size = 64","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:58:48.596064Z","iopub.execute_input":"2022-07-15T09:58:48.596498Z","iopub.status.idle":"2022-07-15T09:58:48.600624Z","shell.execute_reply.started":"2022-07-15T09:58:48.596464Z","shell.execute_reply":"2022-07-15T09:58:48.599814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_dataset(pairs):\n    \n    def gen():\n        for gu,eng in pairs:\n\n            eng = tokenizer.encode_plus(eng, add_special_tokens=True, max_length=sequence_length, return_token_type_ids=True,\n                                        return_attention_mask=True, pad_to_max_length=True, truncation=True)\n            \n            gu = tokenizer.encode_plus(gu, add_special_tokens=True, max_length=sequence_length+1, return_token_type_ids=True,\n                                        return_attention_mask=True, pad_to_max_length=True, truncation=True)\n            \n            inp, out = ({\"encoder_inputs\": eng[\"input_ids\"], \"encoder_mask\": eng[\"attention_mask\"],\n                    \"decoder_inputs\": gu[\"input_ids\"][:-1], \"decoder_mask\": gu[\"attention_mask\"][:-1] }, gu[\"input_ids\"][1:])\n            \n            yield (inp,out)\n        \n    return tf.data.Dataset.from_generator( gen,\n        ({\"encoder_inputs\": tf.int32, \"encoder_mask\": tf.int32, \"decoder_inputs\": tf.int32, \"decoder_mask\": tf.int32}, tf.int32),\n        (\n            {\n                \"encoder_inputs\": tf.TensorShape([None]),\n                \"encoder_mask\": tf.TensorShape([None]),\n                \"decoder_inputs\": tf.TensorShape([None]),\n                \"decoder_mask\": tf.TensorShape([None])\n            },\n            tf.TensorShape([None]),\n        ),\n    )\n\n\ntrain_ds = make_dataset(train_pairs)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:58:48.601540Z","iopub.execute_input":"2022-07-15T09:58:48.602072Z","iopub.status.idle":"2022-07-15T09:58:54.561887Z","shell.execute_reply.started":"2022-07-15T09:58:48.602037Z","shell.execute_reply":"2022-07-15T09:58:54.560999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = train_ds.shuffle(2048).batch(batch_size)\ntest_ds = make_dataset(test_pairs).shuffle(2048).batch(batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:58:54.563198Z","iopub.execute_input":"2022-07-15T09:58:54.563644Z","iopub.status.idle":"2022-07-15T09:58:54.594372Z","shell.execute_reply.started":"2022-07-15T09:58:54.563602Z","shell.execute_reply":"2022-07-15T09:58:54.593679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoder(layers.Layer):\n    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n        super(TransformerEncoder, self).__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.dense_dim = dense_dim\n        self.num_heads = num_heads\n        self.attention = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim//num_heads#, kernel_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=0.02)\n        )\n        self.dense_proj = keras.Sequential(\n            [layers.Dense(dense_dim),#, kernel_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=0.02), activation=\"relu\"),\n             layers.Dense(embed_dim)]#, kernel_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=0.02)),]\n        )\n        self.layernorm_1 = layers.LayerNormalization()\n        self.layernorm_2 = layers.LayerNormalization()\n        self.supports_masking = True\n\n    def call(self, inputs, mask=None):\n        if mask is not None:\n            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n        attention_output = self.attention(\n            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n        )\n        proj_input = self.layernorm_1(inputs + attention_output)\n        proj_output = self.dense_proj(proj_input)\n        return self.layernorm_2(proj_input + proj_output)\n\n\nclass PositionalEmbedding(layers.Layer):\n    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n        super(PositionalEmbedding, self).__init__(**kwargs)\n        self.token_embeddings = layers.Embedding(\n            input_dim=vocab_size, output_dim=embed_dim#, embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=0.02)\n        )\n        self.position_embeddings = layers.Embedding(\n            input_dim=sequence_length, output_dim=embed_dim#, embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=0.02)\n        )\n        self.sequence_length = sequence_length\n        self.vocab_size = vocab_size\n        self.embed_dim = embed_dim\n\n    def call(self, inputs):\n        length = tf.shape(inputs)[-1]\n        positions = tf.range(start=0, limit=length, delta=1)\n        embedded_tokens = self.token_embeddings(inputs)\n        embedded_positions = self.position_embeddings(positions)\n        return embedded_tokens + embedded_positions\n\n    def compute_mask(self, inputs, mask=None):\n        return tf.math.not_equal(inputs, 0)\n\n\nclass TransformerDecoder(layers.Layer):\n    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n        super(TransformerDecoder, self).__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.latent_dim = latent_dim\n        self.num_heads = num_heads\n        self.attention_1 = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim//num_heads#, kernel_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=0.2)\n        )\n        self.attention_2 = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim//num_heads#, kernel_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=0.2)\n        )\n        self.dense_proj = keras.Sequential(\n            [layers.Dense(latent_dim, activation=\"relu\"), #kernel_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=0.2)),\n             layers.Dense(embed_dim)]#, kernel_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=0.2)),]\n        )\n        self.layernorm_1 = layers.LayerNormalization()\n        self.layernorm_2 = layers.LayerNormalization()\n        self.layernorm_3 = layers.LayerNormalization()\n        self.supports_masking = True\n\n    def call(self, inputs, encoder_outputs, mask=None):\n        causal_mask = self.get_causal_attention_mask(inputs)\n        if mask is not None:\n            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n            padding_mask = tf.minimum(padding_mask, causal_mask)\n\n        attention_output_1 = self.attention_1(\n            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n        )\n        out_1 = self.layernorm_1(inputs + attention_output_1)\n\n        attention_output_2 = self.attention_2(\n            query=out_1,\n            value=encoder_outputs,\n            key=encoder_outputs,\n            attention_mask=padding_mask,\n        )\n        out_2 = self.layernorm_2(out_1 + attention_output_2)\n\n        proj_output = self.dense_proj(out_2)\n        return self.layernorm_3(out_2 + proj_output)\n\n    def get_causal_attention_mask(self, inputs):\n        input_shape = tf.shape(inputs)\n        batch_size, sequence_length = input_shape[0], input_shape[1]\n        i = tf.range(sequence_length)[:, tf.newaxis]\n        j = tf.range(sequence_length)\n        mask = tf.cast(i >= j, dtype=\"int32\")\n        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n        mult = tf.concat(\n            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n            axis=0,\n        )\n        return tf.tile(mask, mult)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:58:54.595673Z","iopub.execute_input":"2022-07-15T09:58:54.596199Z","iopub.status.idle":"2022-07-15T09:58:54.619221Z","shell.execute_reply.started":"2022-07-15T09:58:54.596164Z","shell.execute_reply":"2022-07-15T09:58:54.618411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embed_dim = 512\nlatent_dim = 2048\nnum_heads = 8\n\nencoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\nencoder_mask = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_mask\")\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n\nx = TransformerEncoder(embed_dim, latent_dim, num_heads)(x,mask=encoder_mask)\nx = TransformerEncoder(embed_dim, latent_dim, num_heads)(x,mask=encoder_mask)\nencoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x,mask=encoder_mask)    #3 layers\n\nencoder = keras.Model([encoder_inputs, encoder_mask], encoder_outputs)\n\ndecoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\ndecoder_mask = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_mask\")\nencoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n\nx = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs, mask=decoder_mask)\nx = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs, mask=decoder_mask)\nx = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs, mask=decoder_mask)   #3 layers\n\nx = layers.Dropout(0.5)(x)\ndecoder_outputs = layers.Dense(vocab_size,# kernel_initializer=tf.keras.initializers.RandomNormal(mean=0., stddev=0.2),\n                              activation=\"softmax\")(x)\ndecoder = keras.Model([decoder_inputs, encoded_seq_inputs, decoder_mask], decoder_outputs)\n\ndecoder_outputs = decoder([decoder_inputs, encoder_outputs, decoder_mask])\ntransformer = keras.Model(\n    [encoder_inputs, encoder_mask, decoder_inputs, decoder_mask], decoder_outputs, name=\"transformer\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:58:54.620474Z","iopub.execute_input":"2022-07-15T09:58:54.620853Z","iopub.status.idle":"2022-07-15T09:58:56.352393Z","shell.execute_reply.started":"2022-07-15T09:58:54.620817Z","shell.execute_reply":"2022-07-15T09:58:56.351577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 1\n\ntransformer.summary()\ntransformer.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4, epsilon=1e-9, clipnorm=1),\n    loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:58:56.353520Z","iopub.execute_input":"2022-07-15T09:58:56.353857Z","iopub.status.idle":"2022-07-15T09:58:56.382323Z","shell.execute_reply.started":"2022-07-15T09:58:56.353823Z","shell.execute_reply":"2022-07-15T09:58:56.381453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" transformer.fit(train_ds, epochs=epochs)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T18:25:12.684918Z","iopub.execute_input":"2022-06-23T18:25:12.685853Z","iopub.status.idle":"2022-06-24T03:50:24.649551Z","shell.execute_reply.started":"2022-06-23T18:25:12.685787Z","shell.execute_reply":"2022-06-24T03:50:24.648846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nfrom nltk.translate.bleu_score import sentence_bleu\nfrom nltk.translate.bleu_score import SmoothingFunction\nfrom tqdm import tqdm\ndef decode_sequence(input_sentence):\n    tokenized_input_sentence = tokenizer.encode_plus(input_sentence, add_special_tokens=True, max_length=sequence_length, return_token_type_ids=True,\n                                        return_attention_mask=True, pad_to_max_length=True, truncation=True, return_tensors=\"tf\")\n    decoded_sentence = \"[CLS]\"\n    tokens = [2]\n    for i in range(20):\n        tokenized_target_sentence = tokenizer.encode_plus(decoded_sentence, add_special_tokens=False, max_length=sequence_length, return_token_type_ids=True,\n                                        return_attention_mask=True, pad_to_max_length=True, truncation=True, return_tensors=\"tf\")\n        u = [tokenized_input_sentence[\"input_ids\"], tokenized_input_sentence['attention_mask'],\n                                   tokenized_target_sentence[\"input_ids\"], tokenized_target_sentence[\"attention_mask\"]  ]\n        predictions = transformer(u)\n\n        sampled_token_index = np.argmax(predictions[0, i, :])\n        sampled_token = tokenizer.decode([sampled_token_index])\n        decoded_sentence += \" \" + sampled_token\n        tokens.append(sampled_token_index)\n\n        if sampled_token == \"[SEP]\":\n            break\n    return tokenizer.decode(tokens)\n\n\nbleu1 = []\nbleu2 = []\nbleu3 = []\nbleu4 = []\npreds = []\n\nfor i in tqdm(range(len(test_pairs))):\n    target, input_sentence = test_pairs[i]\n    translated = decode_sequence(input_sentence)\n    ac = [target.split()]\n    pr = translated[5:-5].split()\n    preds.append(pr)\n    b1 = sentence_bleu(ac, pr,weights=(1,), smoothing_function=SmoothingFunction().method1)\n    bleu1.append(b1)\n    b2 = sentence_bleu(ac, pr,weights=(0.5,0.5), smoothing_function=SmoothingFunction().method1)\n    bleu2.append(b2)\n    b3 = sentence_bleu(ac, pr,weights=(0.33,0.33,0.33), smoothing_function=SmoothingFunction().method1)\n    bleu3.append(b3)\n    b4 = sentence_bleu(ac, pr,weights=(0.25,0.25,0.25,0.25), smoothing_function=SmoothingFunction().method1)\n    bleu4.append(b4)\n\n#     print(input_sentence)\n#     print(translated)\n#     print(target)\nprint(np.mean(bleu1))\nprint(np.mean(bleu2))\nprint(np.mean(bleu3))\nprint(np.mean(bleu4))","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:59:56.039946Z","iopub.execute_input":"2022-07-15T09:59:56.040322Z","iopub.status.idle":"2022-07-15T11:35:48.532028Z","shell.execute_reply.started":"2022-07-15T09:59:56.040292Z","shell.execute_reply":"2022-07-15T11:35:48.531182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer.save('./2epoch')","metadata":{"execution":{"iopub.status.busy":"2022-06-24T04:00:34.270294Z","iopub.execute_input":"2022-06-24T04:00:34.270678Z","iopub.status.idle":"2022-06-24T04:01:16.970767Z","shell.execute_reply.started":"2022-06-24T04:00:34.270646Z","shell.execute_reply":"2022-06-24T04:01:16.969875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer.load_weights('./2epoch')","metadata":{"execution":{"iopub.status.busy":"2022-07-15T09:59:18.102548Z","iopub.execute_input":"2022-07-15T09:59:18.102918Z","iopub.status.idle":"2022-07-15T09:59:29.702719Z","shell.execute_reply.started":"2022-07-15T09:59:18.102886Z","shell.execute_reply":"2022-07-15T09:59:29.701970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r ./2epoch.zip ./2epoch","metadata":{"execution":{"iopub.status.busy":"2022-06-24T04:10:35.300268Z","iopub.execute_input":"2022-06-24T04:10:35.300702Z","iopub.status.idle":"2022-06-24T04:15:58.441288Z","shell.execute_reply.started":"2022-06-24T04:10:35.300672Z","shell.execute_reply":"2022-06-24T04:15:58.440304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}